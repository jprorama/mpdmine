{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation test sets\n",
    "\n",
    "Build subset of data to test hottracks song recommendation\n",
    "\n",
    "This will create a train and test set to be used in hottracks recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import importlib\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, MinHashLSH\n",
    "from pyspark.sql.types import IntegerType, StringType, ArrayType\n",
    "\n",
    "import mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will allow us to embed images in the notebook\n",
    "%matplotlib inline\n",
    "# change default plot size\n",
    "plt.rcParams['figure.figsize'] = (15,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prep data\n",
    "\n",
    "* Load the full data set\n",
    "* Load the picked k=100 approx Nearest Neighbor results\n",
    "* Build song recommdations based on songs in nearest playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_all=mpd.load(spark, \"onebig\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load challenge data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_test=spark.read.json(\"../mpd-challenge/challenge_set.json\", multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpl=mpd_test.select(f.explode(\"playlists\").alias(\"playlist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpl.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf=cpl.select(\"playlist.name\", \"playlist.num_holdouts\", \"playlist.pid\", \"playlist.num_tracks\", \"playlist.tracks\", \"playlist.num_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.select(\"pid\", recdf.tracks.artist_uri, recdf.tracks.track_uri).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.select(\"pid\", \"name\", f.explode(\"tracks\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into test and train\n",
    "\n",
    "Extract the playlist into a data frame that can be split.  We are working directly with the playlist vector and want a data set similar in structure to the challenge set.\n",
    "\n",
    "This needs to produce a data set that looks like the input of the challenge set.  The working model for the mpd load has been a pre-processed json that doesn't have the full hierarchy of the raw input.  Should be able to create the playlist wrapper after model selection.\n",
    "\n",
    "This will enable using the validate_submission.py utility and othe tools for working with the original data and challenge set.\n",
    "\n",
    "The actual test sets will need to be playlist exported with data withheld\n",
    "\n",
    "We are using the full 1,000,000 less 10k to produce a training set to match the challenge set size and because our \"training\" is really just a k-NN search we want as close to the original count of given playlists for that search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_all.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = mpd_all.randomSplit([1000000.0-10000.0, 10000.0], 1244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, due to normalization we don't seem to be able to get exactly 10k test examples. Actually it appears to vary by the seed value.  The seed 1244 was picked after some simple searching for a value that brings that data close to the desired 10k given in the challenge set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare distributions of origina, test, and challenge set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how what similarity exists in the sub-samples distribution of playlists versus the original challenge set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(mpd_all, \"num_tracks\", 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(train, \"num_tracks\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(test, \"num_tracks\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(recdf, \"num_tracks\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting.  The random split represents the character of the overall data set but the challenge set has a bi-modal shape.  Wonder how to reproduce via a random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(recdf, \"num_holdouts\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that the number of hold outs more closely aligns to the shape of the the playlist lengths in the orignal data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(recdf, \"num_samples\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a more granular histogram the challenge set looks exactly as expected with an even split across the five challenge types of seed tracks [0, 5, 10, 25, 95]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for corellations of playlist length to their selection for different seed categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=recdf.select(\"num_tracks\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=recdf.select(\"num_holdouts\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pyplot.scatter(X,Y)\n",
    "plt.pyplot.xlabel(\"Playlist Length\")\n",
    "plt.pyplot.ylabel(\"Holdouts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there is a correlation as they playlist length increase there are more hold outs. Interesting to see that there are about four groupings with playlist length of 100 being a dividing point between two sets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pyplot.scatter(X, recdf.select(\"num_samples\").toPandas())\n",
    "plt.pyplot.xlabel(\"Playlist Length\")\n",
    "plt.pyplot.ylabel(\"Sample count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it's clear to see where the challenge playlists come from.  We can easily sample from different playlist length categories to get our challenge set.  Again the 100 song playlist is a clear division between the groups for the 25 and 100 sample count challenge set."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
