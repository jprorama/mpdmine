{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation test sets\n",
    "\n",
    "Build subset of data to test hottracks song recommendation\n",
    "\n",
    "This will create a train and test set to be used in hottracks recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import importlib\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, MinHashLSH\n",
    "from pyspark.sql.types import IntegerType, StringType, ArrayType\n",
    "\n",
    "import mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will allow us to embed images in the notebook\n",
    "%matplotlib inline\n",
    "# change default plot size\n",
    "plt.rcParams['figure.figsize'] = (15,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prep data\n",
    "\n",
    "* Load the full data set\n",
    "* Load the picked k=100 approx Nearest Neighbor results\n",
    "* Build song recommdations based on songs in nearest playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_all=mpd.load(spark, \"onebig\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load challenge data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_test=spark.read.json(\"../mpd-challenge/challenge_set.json\", multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpl=mpd_test.select(f.explode(\"playlists\").alias(\"playlist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpl.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf=cpl.select(\"playlist.name\", \"playlist.num_holdouts\", \"playlist.pid\", \"playlist.num_tracks\", \"playlist.tracks\", \"playlist.num_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.select(\"pid\", recdf.tracks.artist_uri, recdf.tracks.track_uri).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.select(\"pid\", \"name\", f.explode(\"tracks\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into test and train\n",
    "\n",
    "Extract the playlist into a data frame that can be split.  We are working directly with the playlist vector and want a data set similar in structure to the challenge set.\n",
    "\n",
    "This needs to produce a data set that looks like the input of the challenge set.  The working model for the mpd load has been a pre-processed json that doesn't have the full hierarchy of the raw input.  Should be able to create the playlist wrapper after model selection.\n",
    "\n",
    "This will enable using the validate_submission.py utility and othe tools for working with the original data and challenge set.\n",
    "\n",
    "The actual test sets will need to be playlist exported with data withheld\n",
    "\n",
    "We are using the full 1,000,000 less 10k to produce a training set to match the challenge set size and because our \"training\" is really just a k-NN search we want as close to the original count of given playlists for that search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_all.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = mpd_all.randomSplit([1000000.0-10000.0, 10000.0], 1244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, due to normalization we don't seem to be able to get exactly 10k test examples. Actually it appears to vary by the seed value.  The seed 1244 was picked after some simple searching for a value that brings that data close to the desired 10k given in the challenge set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare distributions of origina, test, and challenge set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how what similarity exists in the sub-samples distribution of playlists versus the original challenge set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(mpd_all, \"num_tracks\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(train, \"num_tracks\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(test, \"num_tracks\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(recdf, \"num_tracks\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting.  The random split represents the character of the overall data set but the challenge set has a bi-modal shape.  Wonder how to reproduce via a random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(recdf, \"num_holdouts\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that the number of hold outs more closely aligns to the shape of the the playlist lengths in the orignal data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.plothist(recdf, \"num_samples\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a more granular histogram the challenge set looks exactly as expected with an even split across the five challenge types of seed tracks [0, 5, 10, 25, 95]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for corellations of playlist length to their selection for different seed categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=recdf.select(\"num_tracks\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=recdf.select(\"num_holdouts\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pyplot.scatter(X,Y)\n",
    "plt.pyplot.xlabel(\"Playlist Length\")\n",
    "plt.pyplot.ylabel(\"Holdouts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there is a correlation as they playlist length increase there are more hold outs. Interesting to see that there are about four groupings with playlist length of 100 being a dividing point between two sets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pyplot.scatter(X, recdf.select(\"num_samples\").toPandas())\n",
    "plt.pyplot.xlabel(\"Playlist Length\")\n",
    "plt.pyplot.ylabel(\"Sample count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it's clear to see where the challenge playlists come from.  We can easily sample from different playlist length categories to get our challenge set.  Again the 100 song playlist is a clear division between the groups for the 25 and 100 sample count challenge set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm sample size categories\n",
    "\n",
    "Make sure we understand all distinct categories of data based on the number of tracks in the sample. These essentially distinguish the different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.groupBy(\"num_samples\").count().orderBy(\"num_samples\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand min and max of each sample set size range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.where(recdf.num_samples == 100).describe(\"num_tracks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.where(recdf.num_samples == 25).describe(\"num_tracks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.where(recdf.num_samples == 10).describe(\"num_tracks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.where(recdf.num_samples == 5).describe(\"num_tracks\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note inspecting the sample length 5 playlists at the 50 split mark shows there is some clustering (based on mean and stdev -- tighter grouping) of the above 50 playlist length with the sample size 10 playlist category and also the at or below 50 with the five, one and zero sample playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.where(recdf.num_samples == 5).where(recdf.num_tracks > 50).describe(\"num_tracks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.where(recdf.num_samples == 5).where(recdf.num_tracks <= 50).describe(\"num_tracks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.where(recdf.num_samples == 1).describe(\"num_tracks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.where(recdf.num_samples == 0).describe(\"num_tracks\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand distribution of samples in each sample set category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.where(recdf.num_samples == 1).groupBy(\"num_tracks\").count().orderBy(f.desc(\"num_tracks\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recdf.where(recdf.num_samples == 1).groupBy(\"num_tracks\").count().describe(\"count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklen_inclusion_rate= recdf.where(recdf.num_samples == 0).groupBy(\"num_tracks\").count()\n",
    "zero = plt.pyplot.scatter(tracklen_inclusion_rate.select(\"num_tracks\").toPandas(), tracklen_inclusion_rate.select(\"count\").toPandas())\n",
    "tracklen_inclusion_rate= recdf.where(recdf.num_samples == 1).groupBy(\"num_tracks\").count()\n",
    "one = plt.pyplot.scatter(tracklen_inclusion_rate.select(\"num_tracks\").toPandas(), tracklen_inclusion_rate.select(\"count\").toPandas())\n",
    "tracklen_inclusion_rate= recdf.where(recdf.num_samples == 5).groupBy(\"num_tracks\").count()\n",
    "five = plt.pyplot.scatter(tracklen_inclusion_rate.select(\"num_tracks\").toPandas(), tracklen_inclusion_rate.select(\"count\").toPandas())\n",
    "tracklen_inclusion_rate= recdf.where(recdf.num_samples == 10).groupBy(\"num_tracks\").count()\n",
    "ten = plt.pyplot.scatter(tracklen_inclusion_rate.select(\"num_tracks\").toPandas(), tracklen_inclusion_rate.select(\"count\").toPandas())\n",
    "tracklen_inclusion_rate= recdf.where(recdf.num_samples == 25).groupBy(\"num_tracks\").count()\n",
    "twentyfive = plt.pyplot.scatter(tracklen_inclusion_rate.select(\"num_tracks\").toPandas(), tracklen_inclusion_rate.select(\"count\").toPandas())\n",
    "tracklen_inclusion_rate= recdf.where(recdf.num_samples == 100).groupBy(\"num_tracks\").count()\n",
    "hundred = plt.pyplot.scatter(tracklen_inclusion_rate.select(\"num_tracks\").toPandas(), tracklen_inclusion_rate.select(\"count\").toPandas())\n",
    "\n",
    "plt.pyplot.legend((zero, one, five, ten, twentyfive, hundred), ('Zero', 'One', 'Five', 'Ten', 'Twenty-five', 'Hundred'), title=\"Sample Size\")\n",
    "plt.pyplot.xlabel(\"Playlist Length\")\n",
    "plt.pyplot.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are appears to be a clear pattern for the 0-5 and 5-100 sample sizes, with the 5 sample size case falling in both categories.  \n",
    "\n",
    "\n",
    "The second type of playlist inclusion seem to all share a power-law style curve with a decreasing number of playlists chosen as the size increases.  These seem to break down into two subsets for sampling 50-100 length playlists and for the 5 and 10 sample length.  For the 25 and 100 sample length the playlists all seem to come from above 100 and 150. For the 5 and 10 sample length the playlists all seem to be in the 40-100 playslist length whith a much steeper curve.  This may simply be due to the need to get an equal number of playlist over a short length range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems desirable to [use stratified sampling to build a challenge set](https://stats.stackexchange.com/questions/7415/how-to-make-representative-sample-set-from-a-large-overall-dataset).  Based on wikipedia, it's possible that sampling based on the percent each of these playlists lengths covers in the whole popluation may be the best strategey."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
